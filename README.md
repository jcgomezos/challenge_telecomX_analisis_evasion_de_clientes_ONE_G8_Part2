# challenge_telecomX_analisis_evasion_de_clientes_ONE_G8_Part2
Este proyecto tiene como objetivo analizar y predecir la p茅rdida de clientes (Churn) en la empresa Telecom X utilizando modelos de Machine Learning.  Se desarrollaron dos modelos principales: Regresi贸n Log铆stica y Random Forest, con el fin de comparar su desempe帽o y determinar cu谩l es m谩s efectivo para la predicci贸n.
Objetivos del Proyecto
Analizar datos hist贸ricos de clientes para identificar patrones asociados al Churn.

Entrenar y evaluar modelos de clasificaci贸n supervisada.

Comparar m茅tricas clave de rendimiento entre los modelos.

Proporcionar conclusiones y recomendaciones para la empresa.

- Contenido del Proyecto
Exploraci贸n y limpieza de datos:

An谩lisis exploratorio (EDA).

Tratamiento de valores faltantes.

Codificaci贸n de variables categ贸ricas.

Eliminaci贸n de variables que filtraban la respuesta (ej. Churn_No).

Entrenamiento de modelos:

Regresi贸n Log铆stica.

Random Forest.

Evaluaci贸n de modelos:

Accuracy.

Precision.

Recall.

F1-score.

Matriz de confusi贸n.

An谩lisis cr铆tico y conclusiones.

- Resultados de Evaluaci贸n
Regresi贸n Log铆stica
Accuracy: 0.85

Precision: 0.85

Recall: 0.85

F1-score: 0.85

Matriz de Confusi贸n:


[[1332  221]
 [ 239 1313]]
Random Forest
Accuracy: 0.81

Precision: 0.82

Recall: 0.81

F1-score: 0.81

Matriz de Confusi贸n:


[[1167  386]
 [ 193 1359]]

 
- An谩lisis Cr铆tico
La Regresi贸n Log铆stica mostr贸 un rendimiento m谩s equilibrado entre precisi贸n y recall para ambas clases, siendo m谩s estable en la predicci贸n.

El Random Forest present贸 un mejor recall para clientes que abandonan (clase 1), pero sacrific贸 algo de precisi贸n, lo que puede llevar a m谩s falsos positivos.

Ninguno de los modelos mostr贸 signos claros de overfitting en esta fase, ya que no se ajustaron hiperpar谩metros.

La eliminaci贸n de la variable Churn_No fue clave para evitar fuga de informaci贸n (data leakage).

 Conclusiones
La Regresi贸n Log铆stica es el modelo m谩s balanceado y confiable en este caso, adecuado para una primera implementaci贸n.

El Random Forest podr铆a superar a la regresi贸n log铆stica si se ajustan sus hiperpar谩metros (n煤mero de 谩rboles, profundidad m谩xima, etc.).

Es recomendable realizar un ajuste de hiperpar谩metros y validaci贸n cruzada para ambos modelos antes de una implementaci贸n final.

El an谩lisis permiti贸 entender mejor las variables que impactan en la p茅rdida de clientes, lo que es clave para estrategias de retenci贸n.

- Tecnolog铆as Utilizadas
Python 3.x

Pandas, NumPy

Scikit-learn

Matplotlib, Seaborn

Jupyter Notebook

- Pr贸ximos Pasos
Ajuste de hiperpar谩metros con GridSearchCV o RandomizedSearchCV.

